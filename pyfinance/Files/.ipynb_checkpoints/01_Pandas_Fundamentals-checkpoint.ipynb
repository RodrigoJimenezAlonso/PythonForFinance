{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2ffe4f",
   "metadata": {},
   "source": [
    "\n",
    "# Pandas Fundamentals & Data Access (Finance-ready)\n",
    "\n",
    "**Study path:** This notebook compresses everything you need for a FinTech / Quant dev master:\n",
    "- DataFrame essentials (indexing, selecting, adding/removing, `.loc` / `.iloc`, multi-index)\n",
    "- Conditional selection & multiple conditions\n",
    "- Missing data (`dropna`, `fillna`), thresholds & axis\n",
    "- GroupBy (aggregate, describe, count/min/max), wide-to-narrow intuition\n",
    "- Concatenate / Merge / Join (axis, keys, inner/outer/left/right)\n",
    "- Handy operations: `unique`, `nunique`, `value_counts`, `apply` (with lambdas), sorting, `isnull`\n",
    "- Pivot tables\n",
    "- I/O: CSV, Excel, HTML (via `StringIO`), SQL (SQLite) with **SQLAlchemy 2.x** pattern (fallback to `sqlite3`)\n",
    "- Exercises with solutions (E1–E3)\n",
    "- DataReader (example), Quandl API (free endpoints)\n",
    "\n",
    "_Tip:_ Run cell-by-cell. Everything is self-contained and robust as of 2025.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c4b9d",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents\n",
    "1. [Imports & Setup](#imports)\n",
    "2. [DataFrame Basics](#df-basics)\n",
    "3. [Indexing & Selection (`[]`, `.loc`, `.iloc`)](#indexing)\n",
    "4. [Add/Drop Columns & Rows; `axis`; `shape`](#add-drop)\n",
    "5. [Conditional Selection & Multiple Conditions](#conds)\n",
    "6. [Missing Data (`dropna`, `fillna`)](#missing)\n",
    "7. [GroupBy & Aggregations](#groupby)\n",
    "8. [Concatenate / Merge / Join](#merge)\n",
    "9. [Operations: unique, value_counts, apply, sort, isnull](#ops)\n",
    "10. [Pivot Tables](#pivot)\n",
    "11. [I/O: CSV, Excel, HTML, SQL (SQLAlchemy 2.x)](#io)\n",
    "12. [Exercises (E1–E3) + Solutions](#ex)\n",
    "13. [Pandas DataReader (example) & Quandl](#external)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616248a0",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "\n",
    "## 1) Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# Optional SQLAlchemy\n",
    "try:\n",
    "    from sqlalchemy import create_engine, text\n",
    "    SQLALCHEMY_OK = True\n",
    "except Exception:\n",
    "    SQLALCHEMY_OK = False\n",
    "    print(\"SQLAlchemy not available -> SQL cells will use sqlite3 fallback.\")\n",
    "\n",
    "pd.set_option(\"display.precision\", 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7123d6ad",
   "metadata": {},
   "source": [
    "<a id='df-basics'></a>\n",
    "\n",
    "## 2) DataFrame Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(101)\n",
    "df = pd.DataFrame(np.random.randn(5,4), index=list(\"ABCDE\"), columns=list(\"WXYZ\"))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb6dec",
   "metadata": {},
   "source": [
    "<a id='indexing'></a>\n",
    "\n",
    "## 3) Indexing & Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92363dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Column(s)\n",
    "df['W']              # one column -> Series\n",
    "df[['W','Z']]        # list of columns -> DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d66a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rows with .loc (label) and .iloc (position)\n",
    "df.loc['C']\n",
    "df.iloc[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Subsets row x column\n",
    "df.loc['B','Y']                 # single value\n",
    "df.loc[['A','B'], ['W','Y']]    # 2x2 subset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f333d5",
   "metadata": {},
   "source": [
    "<a id='add-drop'></a>\n",
    "\n",
    "## 4) Add / Drop & `axis` / `shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a column from others\n",
    "df['NEW'] = df['W'] + df['Y']\n",
    "df.shape, df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabd411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop column (axis=1); not in-place by default\n",
    "df2 = df.drop('NEW', axis=1)\n",
    "df2.columns, df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In-place drop\n",
    "df.drop('NEW', axis=1, inplace=True)\n",
    "'NEW' in df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop row (axis=0)\n",
    "df.drop('E', axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a0f4c",
   "metadata": {},
   "source": [
    "<a id='conds'></a>\n",
    "\n",
    "## 5) Conditional Selection & Multiple Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entire DF boolean mask\n",
    "mask = df > 0\n",
    "df[mask].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24949b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter rows by a column condition\n",
    "df[df['W'] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Multiple conditions: use & (and) and | (or), each condition in parentheses\n",
    "df[(df['W'] > 0) & (df['Y'] > 0)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3899a87",
   "metadata": {},
   "source": [
    "<a id='missing'></a>\n",
    "\n",
    "## 6) Missing Data (`dropna`, `fillna`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec94bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = {'A':[1,2,np.nan], 'B':[5,np.nan,np.nan], 'C':[1,2,3]}\n",
    "mdf = pd.DataFrame(d)\n",
    "display(mdf)\n",
    "display(mdf.dropna())                 # drop rows with any NaN\n",
    "display(mdf.dropna(axis=1))           # drop columns with any NaN\n",
    "display(mdf.dropna(thresh=2))         # keep rows with >=2 non-NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill with value or statistic\n",
    "mdf['A'] = mdf['A'].fillna(mdf['A'].mean())\n",
    "mdf.fillna('FILL').head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649658d",
   "metadata": {},
   "source": [
    "<a id='groupby'></a>\n",
    "\n",
    "## 7) GroupBy & Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b3cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {'Company':['GOOG','GOOG','MSFT','MSFT','FB','FB'],\n",
    "        'Person':['Sam','Charlie','Amy','Vanessa','Carl','Sarah'],\n",
    "        'Sales':[200,120,340,124,243,350]}\n",
    "gdf = pd.DataFrame(data)\n",
    "grp = gdf.groupby('Company')\n",
    "display(grp.mean(numeric_only=True))\n",
    "display(grp.sum(numeric_only=True))\n",
    "display(grp.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d0249c",
   "metadata": {},
   "source": [
    "<a id='merge'></a>\n",
    "\n",
    "## 8) Concatenate / Merge / Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d38fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1 = pd.DataFrame({'A':['A0','A1','A2','A3'],\n",
    "                   'B':['B0','B1','B2','B3'],\n",
    "                   'C':['C0','C1','C2','C3'],\n",
    "                   'D':['D0','D1','D2','D3']},\n",
    "                  index=[0,1,2,3])\n",
    "f2 = f1.copy(); f2.index = [4,5,6,7]\n",
    "f3 = f1.copy(); f3.index = [8,9,10,11]\n",
    "pd.concat([f1,f2,f3], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "left  = pd.DataFrame({'key':['K0','K1','K2','K3'],'A':['A0','A1','A2','A3'],'B':['B0','B1','B2','B3']})\n",
    "right = pd.DataFrame({'key':['K0','K1','K2','K3'],'C':['C0','C1','C2','C3'],'D':['D0','D1','D2','D3']})\n",
    "pd.merge(left, right, on='key', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da020a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Join by index\n",
    "l = left.set_index('key')\n",
    "r = right.set_index('key')\n",
    "l.join(r, how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca7cd6",
   "metadata": {},
   "source": [
    "<a id='ops'></a>\n",
    "\n",
    "## 9) Operations: unique / value_counts / apply / sort / isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c749db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ops = pd.DataFrame({'col1':[1,2,3,4], 'col2':[444,555,444,666], 'col3':['abc','def','ghi','xyz']})\n",
    "ops['col2'].unique(), ops['col2'].nunique(), ops['col2'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# apply with function / lambda\n",
    "def times2(x): return x*2\n",
    "ops['col1'].apply(times2), ops['col3'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e240cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sort, isnull\n",
    "ops.sort_values('col2')\n",
    "ops.isnull().head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2026525",
   "metadata": {},
   "source": [
    "<a id='pivot'></a>\n",
    "\n",
    "## 10) Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da468cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pt = pd.DataFrame({'A':['foo','foo','bar','bar','foo','bar','foo','bar'],\n",
    "                   'B':['one','one','two','three','two','two','one','three'],\n",
    "                   'C':['x','y','x','y','x','y','x','x'],\n",
    "                   'D':np.random.randn(8)})\n",
    "pt.pivot_table(values='D', index=['A','B'], columns='C')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5d29e",
   "metadata": {},
   "source": [
    "<a id='io'></a>\n",
    "\n",
    "## 11) I/O: CSV, Excel, HTML (`StringIO`), SQL (SQLAlchemy 2.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CSV\n",
    "demo = pd.DataFrame({\"A\":[1,2,3], \"B\":[10,20,30]})\n",
    "demo.to_csv(\"demo.csv\", index=False)\n",
    "pd.read_csv(\"demo.csv\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37522702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Excel\n",
    "demo.to_excel(\"demo.xlsx\", sheet_name=\"Sheet1\", index=False)\n",
    "pd.read_excel(\"demo.xlsx\", sheet_name=\"Sheet1\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d335095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HTML from literal string -> use StringIO (future-proof)\n",
    "html = '''\n",
    "<table>\n",
    "  <tr><th>name</th><th>value</th></tr>\n",
    "  <tr><td>alpha</td><td>1</td></tr>\n",
    "  <tr><td>beta</td><td>2</td></tr>\n",
    "</table>\n",
    "'''\n",
    "pd.read_html(io.StringIO(html))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SQL: SQLite in-memory; SQLAlchemy 2.x pattern (fallback to sqlite3)\n",
    "import sqlite3\n",
    "\n",
    "if SQLALCHEMY_OK:\n",
    "    engine = create_engine(\"sqlite+pysqlite:///:memory:\", echo=False, future=True)\n",
    "    demo.to_sql(\"my_table\", engine, index=False)\n",
    "    pd.read_sql(\"SELECT * FROM my_table\", con=engine)\n",
    "else:\n",
    "    con = sqlite3.connect(\":memory:\")\n",
    "    demo.to_sql(\"my_table\", con, index=False)\n",
    "    pd.read_sql(\"SELECT * FROM my_table\", con)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69661d6",
   "metadata": {},
   "source": [
    "<a id='ex'></a>\n",
    "\n",
    "## 12) Exercises (with solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9413ac",
   "metadata": {},
   "source": [
    "**E1.** Write `demo` to `result.csv` and read it back as `df_loaded`. Verify equality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94077511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "demo.to_csv(\"result.csv\", index=False)\n",
    "df_loaded = pd.read_csv(\"result.csv\")\n",
    "print(\"Equal values:\", df_loaded.equals(demo))\n",
    "df_loaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d81706",
   "metadata": {},
   "source": [
    "**E2.** Append a second sheet (`Sheet2`) to `demo.xlsx` with a new DataFrame and read it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "other = pd.DataFrame({\"C\":[100,200], \"D\":[300,400]})\n",
    "try:\n",
    "    with pd.ExcelWriter(\"demo.xlsx\", mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"replace\") as writer:\n",
    "        other.to_excel(writer, sheet_name=\"Sheet2\", index=False)\n",
    "except Exception:\n",
    "    # Fall back: recreate file with both sheets\n",
    "    with pd.ExcelWriter(\"demo.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "        demo.to_excel(writer, sheet_name=\"Sheet1\", index=False)\n",
    "        other.to_excel(writer, sheet_name=\"Sheet2\", index=False)\n",
    "pd.read_excel(\"demo.xlsx\", sheet_name=\"Sheet2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b319f",
   "metadata": {},
   "source": [
    "**E3.** Create a SQL table `names`, insert two rows, and `SELECT` rows whose `first` starts with `'A'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a3490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if SQLALCHEMY_OK:\n",
    "    engine = create_engine(\"sqlite+pysqlite:///:memory:\", echo=False, future=True)\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(\"CREATE TABLE names (first TEXT, last TEXT)\"))\n",
    "        conn.execute(text(\"INSERT INTO names VALUES (:f, :l)\"), [{\"f\":\"Ada\",\"l\":\"Lovelace\"},{\"f\":\"Alan\",\"l\":\"Turing\"}])\n",
    "    pd.read_sql(\"SELECT * FROM names WHERE first LIKE 'A%'\", con=engine)\n",
    "else:\n",
    "    con = sqlite3.connect(\":memory:\")\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"CREATE TABLE names (first TEXT, last TEXT)\")\n",
    "    cur.executemany(\"INSERT INTO names VALUES (?,?)\", [(\"Ada\",\"Lovelace\"),(\"Alan\",\"Turing\")])\n",
    "    con.commit()\n",
    "    pd.read_sql(\"SELECT * FROM names WHERE first LIKE 'A%'\", con)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9802bb1f",
   "metadata": {},
   "source": [
    "<a id='external'></a>\n",
    "\n",
    "## 13) Pandas DataReader (example) & Quandl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f7144",
   "metadata": {},
   "source": [
    "\n",
    "**Note:** Internet access may be disabled in your environment. Treat the following as reference templates.\n",
    "\n",
    "### Pandas DataReader (Google/other sources may change; adjust source accordingly)\n",
    "```python\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime(2015,1,1)\n",
    "end   = datetime(2017,1,1)\n",
    "fb = web.DataReader('FB', 'stooq', start, end)  # example: 'stooq' often works\n",
    "fb.head()\n",
    "```\n",
    "\n",
    "### Quandl (free usage up to a daily limit)\n",
    "```python\n",
    "import quandl\n",
    "# Simple time series (e.g., WTI crude from DOE)\n",
    "oil = quandl.get('EIA/PET_RWTC_D')\n",
    "oil.plot()\n",
    "\n",
    "# Wiki end-of-day (legacy): 'WIKI/AAPL' (dataset availability can change)\n",
    "aapl = quandl.get('WIKI/AAPL')\n",
    "aapl[['Adj. Close','Adj. Volume']].tail()\n",
    "```\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
